{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOULx4oWdGifqBLn2Ov7BYN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caua-sathler/Jarvis-Desktop-Voice-Assistant/blob/main/MLP-DP-PSO-SGD/DP_MLP_PSO_Adam_Ionosphere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bUshj06w8EUh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "3MwqLzgb8QnZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "q27wMqjK8SvI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\"\n",
        "column_names = [f\"feature_{i}\" for i in range(34)] + [\"label\"]\n",
        "\n",
        "ionosphere = pd.read_csv(url, header=None, names=column_names)\n",
        "\n",
        "ionosphere[\"label\"] = ionosphere[\"label\"].map({\"b\": 0, \"g\": 1})"
      ],
      "metadata": {
        "id": "RqYR78Tu8Ukg"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = ionosphere.drop(columns=['label']).values\n",
        "y = ionosphere['label'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "pcCeJm4E8YUA"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32)\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 32)\n",
        "        self.fc5 = nn.Linear(32, 16)\n",
        "        self.fc6 = nn.Linear(16, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "i7giQxZ68jQI"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Particle:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = copy.deepcopy(model).to(device)\n",
        "        self.best_model = copy.deepcopy(model).to(device)\n",
        "\n",
        "        low, high = -10.0, 10.0\n",
        "        velocity_scale = 0.1\n",
        "        self.position = {name: torch.rand_like(param).to(device) * (high - low) + low\n",
        "                         for name, param in model.named_parameters()}\n",
        "        self.velocity = {name: torch.randn_like(param).to(device) * velocity_scale\n",
        "                         for name, param in model.named_parameters()}\n",
        "\n",
        "        self.best_loss = float('inf')\n",
        "        self.device = device\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "\n",
        "        # Parâmetros para o ruído diferencialmente privado\n",
        "        self.epsilon = 3\n",
        "        self.delta = 1e-5\n",
        "        self.sensitivity = 3\n",
        "        # self.alpha = 0.99  # Fator de redução do ruído\n",
        "        self.iteration = 0  # Contador de iterações\n",
        "\n",
        "    def pso(self, global_best_model, inertia, c1, c2):\n",
        "        self.iteration += 1  # Atualiza a contagem de iterações\n",
        "        # noise_decay = self.alpha ** self.iteration  # Reduz gradualmente o impacto do ruído\n",
        "\n",
        "        for name, param in self.model.named_parameters():\n",
        "            local_rand, global_rand = random.random(), random.random()\n",
        "\n",
        "            # Atualiza a velocidade\n",
        "            self.velocity[name] = (\n",
        "                inertia * self.velocity[name]\n",
        "                + c1 * local_rand * (self.best_model.state_dict()[name].to(self.device) - param.data)\n",
        "                + c2 * global_rand * (global_best_model.state_dict()[name].to(self.device) - param.data)\n",
        "            )\n",
        "\n",
        "            # Gerar ruído normalizado\n",
        "            sigma = self.sensitivity * torch.sqrt(torch.tensor(2.0 * torch.log(torch.tensor(1.0 / self.delta)))) / self.epsilon\n",
        "            noise = torch.normal(mean=0, std=sigma, size=self.velocity[name].shape, device=self.device)\n",
        "\n",
        "            # Normaliza o ruído\n",
        "            noise_norm = noise / (torch.norm(noise) + 1e-8)\n",
        "\n",
        "            # Aplica ruído reduzido ao longo das iterações\n",
        "            self.velocity[name] += noise_norm #* noise_decay\n",
        "\n",
        "            # Clipping adaptativo para evitar explosões na velocidade\n",
        "            self.velocity[name] = torch.clamp(self.velocity[name], -1.5, 1.5)\n",
        "\n",
        "            # Atualiza posição\n",
        "            self.position[name] = param.data + self.velocity[name]\n",
        "            param.data = self.position[name]\n",
        "\n",
        "    def evaluate_weights(self, x, y, criterion):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            acc = (predicted == y).sum().item() / len(x)\n",
        "        return loss.item(), acc*100"
      ],
      "metadata": {
        "id": "WNdWjR7fVDGQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros do PSO\n",
        "pop_size = 10\n",
        "num_epochs = 150\n",
        "inertia = 0.9\n",
        "c1, c2 = 0.5, 0.9\n",
        "# learning_rate = 0.0003\n",
        "# beta1, beta2 = 0.5, 0.999\n",
        "# epsilon = 1e-8"
      ],
      "metadata": {
        "id": "hiG03K9BXFpT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_dim=34, output_dim=2)\n",
        "\n",
        "particles = [Particle(model, device) for _ in range(pop_size)]\n",
        "global_best_model = copy.deepcopy(particles[0].model)\n",
        "global_best_score = float('inf')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# m = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
        "# v = {name: torch.zeros_like(param) for name, param in model.named_parameters()}\n",
        "\n",
        "# Armazenar melhor acurácia\n",
        "overall_global_best_accuracy = 0.0\n",
        "overall_global_best_model = copy.deepcopy(global_best_model)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Ajustar inércia ao longo do tempo\n",
        "    inertia = 0.9 - ((0.9 - 0.4)/num_epochs)*epoch\n",
        "\n",
        "    for particle in particles:\n",
        "        particle.model.train()\n",
        "        particle.optimizer.zero_grad()\n",
        "\n",
        "        # PSO+SGD\n",
        "        # particle.calculate_grad(X_train, y_train, criterion)\n",
        "        particle.pso(global_best_model, inertia, c1, c2)\n",
        "\n",
        "        # Refinamento dos pesos com o Adam\n",
        "        outputs = particle.model(X_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "        loss.backward()\n",
        "        particle.optimizer.step()\n",
        "\n",
        "        val_loss, val_acc = particle.evaluate_weights(X_train, y_train, criterion)\n",
        "\n",
        "        # Avaliar e atualizar local best (com base no loss)\n",
        "        if val_loss < particle.best_loss:\n",
        "            particle.best_loss = val_loss\n",
        "            particle.best_model = copy.deepcopy(particle.model)\n",
        "\n",
        "    # Determinar g-best (menor perda)\n",
        "    best_particle = min(particles, key=lambda p: p.best_loss)\n",
        "    if best_particle.best_loss < global_best_score:\n",
        "        global_best_score = best_particle.best_loss\n",
        "        global_best_model = copy.deepcopy(best_particle.best_model)\n",
        "\n",
        "    # Acurácia do g-best no teste\n",
        "    test_loss, test_acc = best_particle.evaluate_weights(X_test, y_test, criterion)\n",
        "\n",
        "    # Verificar se essa acurácia é a maior de todas.\n",
        "    if test_acc > overall_global_best_accuracy:\n",
        "        overall_global_best_accuracy = test_acc\n",
        "        overall_global_best_model = copy.deepcopy(best_particle.best_model)\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {test_loss:.2f}, Acc: {test_acc:.2f}\")\n",
        "\n",
        "print(\"\\nTreinamento concluído!\")\n",
        "print(f\"Maior Acurácia Obtida: {overall_global_best_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXUDs_rhXQui",
        "outputId": "79c88e6e-b911-4842-f1bc-b78890a7d86a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-dc22f31a95d2>:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  sigma = self.sensitivity * torch.sqrt(torch.tensor(2.0 * torch.log(torch.tensor(1.0 / self.delta)))) / self.epsilon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/150, Loss: 1.65, Acc: 63.21\n",
            "Epoch 20/150, Loss: 0.56, Acc: 84.91\n",
            "Epoch 30/150, Loss: 2.13, Acc: 35.85\n",
            "Epoch 40/150, Loss: 1.50, Acc: 74.53\n",
            "Epoch 50/150, Loss: 1.79, Acc: 41.51\n",
            "Epoch 60/150, Loss: 0.62, Acc: 76.42\n",
            "Epoch 70/150, Loss: 1.84, Acc: 66.98\n",
            "Epoch 80/150, Loss: 0.46, Acc: 86.79\n",
            "Epoch 90/150, Loss: 2.01, Acc: 41.51\n",
            "Epoch 100/150, Loss: 1.95, Acc: 65.09\n",
            "Epoch 110/150, Loss: 0.80, Acc: 70.75\n",
            "Epoch 120/150, Loss: 2.47, Acc: 49.06\n",
            "Epoch 130/150, Loss: 0.96, Acc: 65.09\n",
            "Epoch 140/150, Loss: 0.90, Acc: 70.75\n",
            "Epoch 150/150, Loss: 1.40, Acc: 75.47\n",
            "\n",
            "Treinamento concluído!\n",
            "Maior Acurácia Obtida: 91.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inWvEXs-h3qB"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}